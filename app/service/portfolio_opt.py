from typing import List
import numpy as np
import os
import pandas as pd
from app.ai.gold_view_llm import GoldViewLLM
from app.data_fetcher.trade_calender_reader import TradeCalendarReader
from datetime import datetime
from app.models.service_models import PortfolioWeights
from app.database import get_db
import json
import logging
from tqdm import tqdm

from app.data_fetcher.factor_data_reader import FactorDataReader
from app.data_fetcher.csi_index_data_fetcher import CSIIndexDataFetcher
from app.dao.fund_info_dao import FundHistDao
from numba import njit
from vectorbt.portfolio.enums import Direction, OrderStatus, NoOrder, CallSeqType, SizeType
from vectorbt.portfolio import nb
from app.backtest.backtest_engine import run_backtest as run_backtest_engine
from app.backtest.backtest_engine import BacktestConfig
from app.dao.betas_dao import FundBetaDao
from app.service.portfolio_crud import query_latest_portfolio_by_id
from app.data_fetcher import CalendarFetcher
from app.ml.black_litterman_opt_util import load_fund_betas, load_fund_const, compute_prior_mu_sigma, compute_prior_mu_fixed_window, build_bl_views, compute_bl_posterior, optimize_mean_variance
from app.service.portfolio_crud import query_weights_by_date, store_portfolio, query_cov_matrix_by_date
from app.service.portfolio_assets_service import get_portfolio_assets
from app.ml.factor_black_litterman import compute_asset_mu_from_factor_bl
from app.ml.dataset_builder import DatasetBuilder

logger = logging.getLogger(__name__)

def _load_betas_by_code(code):
    df = FundBetaDao.select_by_code_date(code, None)
    df = df.set_index("date", drop=True)
    return df[["MKT", "SMB", "HML", "QMJ"]]

def optimize(asset_source_map: dict, code_factors_map: dict, trade_date: str, 
             post_view_tau: float,
             variance: float, window: int = 20, view_codes: List[str] = None, view_var_scale: float = 0.7, prior_mix: float = 0.3):
    factor_data_reader = FactorDataReader()
    csi_index_data_fetcher = CSIIndexDataFetcher()
    dataset_builder = DatasetBuilder()
    # 1. æ ¹æ®ä¸åŒæ•°æ®æ¥æºä½¿ç”¨ä¸åŒçš„å¤„ç†æ–¹å¼ï¼Œfactor/index, ä½¿ç”¨Black Litterman æ¨¡å‹è¿›è¡Œè®¡ç®—ï¼Œcashä½¿ç”¨æ»šåŠ¨ä¸€å¹´å¹³å‡çš„æ”¶ç›Šè¿›è¡Œè®¡ç®—ï¼Œhistä¸ºå ä½ç¬¦æš‚æ— è®¡ç®—æ–¹æ¡ˆ
    factor_codes = [code for code, src in asset_source_map.items() if src == "factor"]
    index_codes = [code for code, src in asset_source_map.items() if src == "index"]
    hist_codes = [code for code, src in asset_source_map.items() if src == "hist"]
    cash_codes = [code for code, src in asset_source_map.items() if src == "cash"]

    fund_codes = list(asset_source_map.keys())  # å‚ä¸ä¼˜åŒ–çš„èµ„äº§åˆ—è¡¨
    net_value_df = pd.DataFrame()
    # åŠ è½½å„èµ„äº§çš„æ”¶ç›Šå‡€å€¼æ›²çº¿
    if factor_codes:
        df_beta = load_fund_betas(factor_codes, trade_date, lookback_days=365)
        df_factors = factor_data_reader.read_daily_factors(end=trade_date)[["MKT", "SMB", "HML", "QMJ"]].dropna()
        for code in factor_codes:
            beta = df_beta.loc[code].values
            cumret = df_factors.values @ beta
            net_value_df[code] = (1 + pd.Series(cumret, index=df_factors.index)).cumprod()

    for code in index_codes:
        df = csi_index_data_fetcher.get_data_by_code_and_date(code=code, end=trade_date)
        df = df[["date", "close"]].dropna().set_index("date")
        df = df.sort_index()
        net_value_df[code] = df["close"]

    dao = FundHistDao._instance
    for code in hist_codes:
        df = dao.select_dataframe_by_code(code, end_date=trade_date)
        df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
        net_value_df[code] = df["net_value"]

    for code in cash_codes:
        df = dao.select_dataframe_by_code(code, end_date=trade_date)
        df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
        net_value_df[code] = df["net_value"]

    net_value_df = net_value_df.ffill().sort_index()

    # 2. æ„é€ å…ˆéªŒæ”¶ç›Šä¸åæ–¹å·®çŸ©é˜µï¼ˆä½¿ç”¨å‡€å€¼æ›²çº¿ï¼‰
    mu_dummy, Sigma_full, code_list_mu = compute_prior_mu_sigma(
        net_value_df,
        horizon_days=window,
        lookback_years=8.0,
        method="linear",
        asset_source_map=asset_source_map,

    )
    fund_indices = [code_list_mu.index(code) for code in fund_codes]
    mu_dummy_aligned = mu_dummy[fund_indices]
    Sigma_full = Sigma_full[np.ix_(fund_indices, fund_indices)]
    mu_dict = {code: mu_dummy_aligned[i] for i, code in enumerate(fund_codes)}

    # ä»code_factors_mapæ‰¾å‡º10Ybondå¯¹åº”çš„æŒ‡æ•°ä»£ç 
    ten_year_bond_codes = [code for code, factors in code_factors_map.items() if "10YBOND" in factors]
    if not ten_year_bond_codes:
        raise ValueError("10Ybond must have at least one asset code")
    ten_year_bond_index_code = ten_year_bond_codes[0]

    # ====== æ–°å¢ï¼šå› å­å±‚ BL â†’ èµ„äº§ Î¼_post ======
    # ten_year_bond_index_code è¿™é‡Œéœ€è¦ä½ æŒ‰ç…§å®é™…ä»£ç å¡«ï¼Œä¾‹å¦‚ "H11006.CSI" ä¹‹ç±»
    if post_view_tau > 0:
        mu_post_full, code_list_mu_post, mu_factor_post_dict = compute_asset_mu_from_factor_bl(
            asset_source_map=asset_source_map,
            code_factors_map=code_factors_map,
            asset_codes=view_codes,
            trade_date=trade_date,
            dataset_builder=dataset_builder,          # ä½ ç°æœ‰ç”¨äº get_softprob_dict çš„å®ä¾‹
            ten_year_bond_index_code=ten_year_bond_index_code,       # â˜… çœŸå®çš„ 10Y æŒ‡æ•°ä»£ç 
            horizon_days=20,
            lookback_years=8.0,
            tau=post_view_tau,
            alpha_10ybond=0.3,
            beta_lookback_days=250,
            view_var_scale=view_var_scale,
            prior_mix=prior_mix,
        )

        # ç°åœ¨é¡ºåºæ˜¯code_list_mu_postï¼Œä¸fund_codeså¯¹é½
        code_idx_map = {code: i for i, code in enumerate(code_list_mu_post)}
        for code in fund_codes:
            if code in code_idx_map:
                mu_dict[code] = mu_post_full[code_idx_map[code]]

    # è®¡ç®—ç°é‡‘ç±»èµ„äº§çš„å¹³å‡æ”¶ç›Šä»…ç”¨æ»šåŠ¨æœ€è¿‘ä¸€å¹´çš„æ•°æ®è¿›è¡Œè®¡ç®—ï¼Œç”±äºè®¡ç®—æ–¹å¼ä¸å…¶å®ƒèµ„äº§ä¸åŒï¼Œè¿™é‡Œå•ç‹¬å¤„ç†
    cash_net_value_df = net_value_df[cash_codes].dropna()
    cash_mu_series = compute_prior_mu_fixed_window(cash_net_value_df, window=window, lookback_days=252, method="linear")
    for code in cash_codes:
        mu_dict[code] = cash_mu_series[code]
    
    # === ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹åˆ†æé»„é‡‘æœŸè´§ç»“æ„ï¼Œå¾—åˆ°æœŸæœ›æ”¶ç›Šç‡ï¼Œè¦†ç›–mu_post_fullä¸­çš„é»„é‡‘æ”¶ç›Šç‡
    try:
        # ä»code_factors_mapæ‰¾å‡ºGOLDå¯¹åº”çš„æŒ‡æ•°ä»£ç 
        gold_codes = [code for code, factors in code_factors_map.items() if "GOLD" in factors]
        if not gold_codes:
            raise ValueError("GOLD must have at least one asset code")
        gold_code = gold_codes[0]
        gold_idx = fund_codes.index(gold_code)
        gv = GoldViewLLM()
        res = gv.generate_view(gold_code, pd.to_datetime(trade_date).date())
        if res.expected_return is not None and res.view != "no_view":
            mu_dict[gold_code] = res.expected_return
        else:
            logger.warning(f"å¤§æ¨¡å‹æœªè¿”å› {gold_code} çš„è§‚ç‚¹é¢„æµ‹ï¼Œä½¿ç”¨å…ˆéªŒæ”¶ç›Šç‡è¿›è¡Œä¼˜åŒ–")
    except Exception as e:
        logger.error(e)
        # å¤§æ¨¡å‹æ— æ³•å›æº¯å†å²æ•°æ®è¿›è¡Œåˆ†æï¼Œç›´æ¥ç”¨å…ˆéªŒ

    mu_post_full = np.array([mu_dict[code] for code in fund_codes], dtype=float)

    # === Î± è°ƒæ•´ï¼ˆä¸€æ¬¡æ€§æ°´å¹³é¡¹ï¼Œä¸è¿›å…¥åæ–¹å·®ï¼‰,è¿™é‡Œçš„Î±æŒ‡çš„æ˜¯å› å­å½’å› åˆ†æåå‰©ä¸‹çš„å¸¸æ•°é¡¹ ===
    fund_const = load_fund_const(factor_codes, trade_date)
    const_dict = fund_const.rolling(window=window, min_periods=window).sum().dropna(how='all').mean().to_dict()
    const_dict = _robust_clip_const(const_dict)
    lambda_alpha = 0.2  # å¯è°ƒï¼š0.1~0.3 è¾ƒç¨³å¥

    # éfactorç±»å‹èµ„äº§æ²¡æœ‰constï¼Œé»˜è®¤ä¸º0
    alpha_day = np.array([const_dict.get(code, 0.0) for code in fund_codes], dtype=float)

    # åªè°ƒæ•´ Î¼ï¼Œä¸è°ƒæ•´ Î£ï¼Œé¿å…â€œalpha ä¸€è¨€å ‚â€çš„æ³¢åŠ¨æ”¾å¤§
    mu_post_full = mu_post_full + lambda_alpha * alpha_day
    
    # 4. Max Sharpe ç»„åˆä¼˜åŒ–
    # weights, expected_return, expected_vol = optimize_max_sharpe(mu_post_full, Sigma_full)
    weights, expected_return, expected_vol = optimize_mean_variance(mu_post_full, Sigma_full, variance)

    return {
        'codes': fund_codes,
        'weights': dict(zip(fund_codes, weights)),
        'expected_return': expected_return,
        'expected_volatility': expected_vol,
        'sharpe_ratio': expected_return / expected_vol,
        'cov_matrix': Sigma_full,
    }

def optimize_portfolio_realtime(portfolio_id: int):
    """
    å®æ—¶ç»„åˆä¼˜åŒ–ä¸»æµç¨‹ï¼šå®Œæˆä»æ•°æ®è·å–ã€å› å­è®¡ç®—ã€é¢„æµ‹ã€ä¼˜åŒ–çš„å…¨è¿‡ç¨‹ã€‚
    """
    # Step 1: è·å–å…¨å¸‚åœºå®æ—¶è¡Œæƒ…æ•°æ®
    stock_rt, index_rt = fetch_realtime_market_data()

    # Step 2: è®¡ç®—å„è‚¡ç¥¨ç»„åˆæ”¶ç›Šç‡
    portfolio_returns = compute_portfolio_returns(stock_rt)

    # Step 3: è®¡ç®—å®æ—¶å› å­æ”¶ç›Šç‡ï¼ˆMKT, SMB, HML, QMJï¼‰
    realtime_factors = calculate_intraday_factors(portfolio_returns, index_rt)

    # Step 4: ä¼°ç®—å®æ—¶æŒ‡æ•°æ•°æ®
    index_to_etf = {
        "H11001.CSI": "511010.SH",  # ä¸­è¯ç»¼åˆå€º â†’ å›½å€ºETF
        "H11004.CSI": "511260.SH",  # ä¸­è¯10å€º â†’ åå¹´å›½å€ºETF
        "Au99.99.SGE": "518880.SH",  # é»„é‡‘ â†’ é»„é‡‘ETF
    }
    est_index_values = estimate_intraday_index_value(index_to_etf)

    # Step 5: æ„é€ å‡ºå®æ—¶å› å­æ•°æ®åŠå®æ—¶èµ„äº§æ”¶ç›Šæ•°æ®ï¼ˆç”¨äºç‰¹å¾æ„é€ ï¼‰
    additonal_factor_df, additonal_map = build_real_time_date(realtime_factors, est_index_values)

    # Step 6: æ‰§è¡Œç»„åˆä¼˜åŒ–ï¼Œè¾“å‡ºæœ€ä¼˜èµ„äº§æƒé‡
    asset_info = get_portfolio_assets(portfolio_id)
    asset_source_map = asset_info["asset_source_map"]
    code_factors_map = asset_info["code_factors_map"]
    view_codes = asset_info["view_codes"]
    params = asset_info["params"]
    if params is None or "post_view_tau" not in params or "alpha" not in params or "variance" not in params:
        raise Exception("Invalid params, please set post_view_tau and alpha and variance in params")
    post_view_tau = float(params["post_view_tau"])
    variance = float(params["variance"])
    alpha = float(params["alpha"])
    trade_date = datetime.strftime(TradeCalendarReader.get_trade_dates(end=datetime.strftime(datetime.today(), "%Y%m%d"))[-1], "%Y-%m-%d")
    portfolio_plan = optimize_allocation(additonal_factor_df, additonal_map, asset_source_map, code_factors_map, trade_date, post_view_tau, variance, view_codes)

    # è¾“å‡ºæˆ–ä¿å­˜ä¼˜åŒ–ç»“æœ
    w_smooth = output_optimized_portfolio(portfolio_id, portfolio_plan, alpha)

    return w_smooth

# --- å„å­å‡½æ•°å®šä¹‰åŒºåŸŸ ---

def fetch_realtime_market_data():
    """è·å–å…¨å¸‚åœºè‚¡ç¥¨å®æ—¶è¡Œæƒ…æ•°æ®ä¸æŒ‡æ•°è¡Œæƒ…æ•°æ®"""
    from app.data_fetcher.stock_data_reader import StockDataReader
    from app.data_fetcher.index_data_reader import IndexDataReader

    stock_reader = StockDataReader()
    index_reader = IndexDataReader()

    try:
        stock_rt = stock_reader.fetch_realtime_prices()  # è¿”å›å­—æ®µåŒ…å« stock_code, close, vol, amount
        index_rt = index_reader.fetch_realtime_prices("000985.CSI")  # ä¸­è¯å…¨æŒ‡
    except Exception as e:
        import logging
        logging.exception("å®æ—¶è¡Œæƒ…æ•°æ®è·å–å¤±è´¥ï¼Œç»ˆæ­¢ç»„åˆä¼˜åŒ–æµç¨‹")
        raise RuntimeError("å®æ—¶æ•°æ®è·å–å¤±è´¥") from e

    return stock_rt, index_rt

def compute_portfolio_returns(market_data):
    """åŸºäºå®æ—¶è¡Œæƒ…æ•°æ®ï¼Œè®¡ç®—é¢„è®¾ç»„åˆçš„æ”¶ç›Šç‡ï¼ˆç”¨äºæ„å»ºé£æ ¼å› å­ï¼‰"""

    from app.data_fetcher.stock_data_reader import StockDataReader

    # è·å– bt_result ä¸‹æœ€æ–°æ—¥æœŸç›®å½•
    bt_root = "bt_result"

    # æ‰€éœ€ç»„åˆåç§°åˆ—è¡¨
    target_portfolios = [
        "bm_BH_weights.csv",
        "bm_BL_weights.csv",
        "bm_BM_weights.csv",
        "bm_SH_weights.csv",
        "bm_SL_weights.csv",
        "bm_SM_weights.csv",
        "qmj_BH_weights.csv",
        "qmj_BL_weights.csv",
        "qmj_BM_weights.csv",
        "qmj_SH_weights.csv",
        "qmj_SL_weights.csv",
        "qmj_SM_weights.csv"
    ]

    # è·å–å®æ—¶è¡Œæƒ… close
    price_map_rt = market_data.set_index("stock_code")["close"].to_dict()

    # è·å–æ˜¨æ—¥æ”¶ç›˜ä»·ï¼ˆç¼“å­˜æ•°æ®ï¼‰
    today = datetime.now().date()
    latest_trade_date = TradeCalendarReader.get_trade_dates(end=today.strftime("%Y-%m-%d"))[-2]  #T-1æ—¥æœŸ
    adjust_trade_date = TradeCalendarReader.get_trade_dates(end=today.strftime("%Y-%m-%d"))[-1]  #Tæ—¥
    stock_reader = StockDataReader()
    price_df_yesterday = stock_reader.fetch_latest_close_prices_from_cache(latest_trade_date=latest_trade_date, adjust_trade_date=adjust_trade_date)
    price_map_yesterday = price_df_yesterday.set_index("stock_code")["close"].to_dict()

    # å®æ—¶æ•°æ®ä¸­ä¸åŒ…å«åœç‰Œé€€å¸‚æ•°æ®ï¼Œæ ¹æ®å†å²æ•°æ®è¡¥å……
    for yesterday_key in price_map_yesterday:
        if yesterday_key not in price_map_rt:
            price_map_rt[yesterday_key] = price_map_yesterday[yesterday_key]

    result = {}

    for fname in target_portfolios:
        fpath = os.path.join(bt_root, fname)
        if not os.path.exists(fpath):
            continue

        df = pd.read_csv(fpath, index_col=0)
        if df.empty:
            continue
        latest_row = df.iloc[-1]

        weights = latest_row[latest_row > 0]
        codes = weights.index

        try:
            yesterday_value = sum([weights[code] * price_map_yesterday.get(code, 0) for code in codes])
            today_value = sum([weights[code] * price_map_rt.get(code, 0) for code in codes])
            portfolio_ret = today_value / yesterday_value - 1
            result[fname.replace("_weights.csv", "")] = portfolio_ret
        except Exception as e:
            import logging
            logging.warning(f"ç»„åˆæ”¶ç›Šè®¡ç®—å¤±è´¥ï¼š{fname}ï¼Œé”™è¯¯ï¼š{e}")

    return pd.Series(result)

def calculate_intraday_factors(portfolio_returns, index_rt):
    """æ ¹æ®ç»„åˆæ”¶ç›Šç‡è®¡ç®—å®æ—¶é£æ ¼å› å­ï¼ˆå¦‚ MKTã€SMBã€HMLã€QMJï¼‰"""
    import pandas as pd
    from app.data_fetcher.index_data_reader import IndexDataReader

    def _mean_diff(factor_group1: List[str], factor_group2: List[str]) -> float:
        g1 = portfolio_returns[factor_group1]
        g2 = portfolio_returns[factor_group2]
        return g1.mean() - g2.mean() if not g1.empty and not g2.empty else float("nan")

    # è·å–ä¸­è¯å…¨æŒ‡æ˜¨æ—¥æ”¶ç›˜ä»·
    today = datetime.now().date()
    latest_trade_date = TradeCalendarReader.get_trade_dates(end=today.strftime("%Y-%m-%d"))[-2]  #T-1æ—¥æœŸ
    index_reader = IndexDataReader()
    index_close_df = index_reader.fetch_latest_close_prices("000985.CSI", latest_trade_date=latest_trade_date)
    pre_close = index_close_df.loc[0, "close"]
    today_close = index_rt.loc[0, "close"]

    factors = {
        "MKT": today_close / pre_close - 1,
        "SMB": _mean_diff(["bm_SH", "bm_SM", "bm_SL", "qmj_SH", "qmj_SM", "qmj_SL"], ["bm_BH", "bm_BM", "bm_BL", "qmj_BH", "qmj_BM", "qmj_BL"]),
        "HML": _mean_diff(["bm_BH", "bm_SH"], ["bm_BL", "bm_SL"]),
        "QMJ": _mean_diff(["qmj_BH", "qmj_SH"], ["qmj_BL", "qmj_SL"]),
    }

    return pd.Series(factors)


def estimate_intraday_index_value(index_to_etf: dict[str, str]) -> dict[str, float]:
    """
    æ ¹æ®ETFä»·æ ¼æ¨ä¼°ç›˜ä¸­æŒ‡æ•°ç‚¹æ•°ã€‚

    :param index_to_etf: æ˜ å°„å­—å…¸ {index_code: etf_code}
    :return: {index_code: estimated_intraday_value, latest_close_price}
    """
    from app.data_fetcher.index_data_reader import IndexDataReader
    from app.data_fetcher.etf_data_reader import EtfDataReader

    result = {}
    today = datetime.now().date()
    latest_trade_date = TradeCalendarReader.get_trade_dates(end=today.strftime("%Y-%m-%d"))[-2]  #T-1æ—¥æœŸ
    index_reader = IndexDataReader()
    etf_reader = EtfDataReader()
    current_trade_date = TradeCalendarReader.get_trade_dates(end=datetime.strftime(datetime.today(), "%Y%m%d"))[-1]

    for index_code, etf_code in index_to_etf.items():
        # è¯»å–æŒ‡æ•°æ˜¨æ—¥æ”¶ç›˜ç‚¹æ•°
        idx_df = index_reader.fetch_latest_close_prices(index_code, latest_trade_date=latest_trade_date)
        if idx_df.empty:
            continue
        idx_close = idx_df.loc[0, "close"]
        idx_date = pd.to_datetime(idx_df.loc[0, "date"])

        # è¯»å–ETFæ˜¨æ—¥æ”¶ç›˜ä»·
        etf_df = etf_reader.fetch_latest_close_prices(etf_code, latest_trade_date=latest_trade_date)
        if etf_df.empty:
            continue
        etf_close = etf_df.loc[0, "close"]
        etf_date = pd.to_datetime(etf_df.loc[0, "date"])

        # è·å–ETFå®æ—¶ä»·å’Œæ—¥æœŸ
        etf_rt = etf_reader.fetch_realtime_prices(etf_code)
        if etf_rt.empty:
            continue
        rt_price = etf_rt.loc[0, "close"]
        rt_date = pd.to_datetime(etf_rt.loc[0, "date"]) if "date" in etf_rt.columns else current_trade_date

        # åˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€äº¤æ˜“æ—¥ï¼šè‹¥æ˜¯åˆ™è¯´æ˜æŒ‡æ•°å°šæœªæ›´æ–°ï¼Œç›´æ¥è¿”å›æ˜¨æ—¥æŒ‡æ•°
        if idx_date.date() != etf_date.date():
            logging.error(f"æŒ‡æ•°å’ŒETFæ•°æ®æœªåŒæ­¥ï¼Œè¯·ç¡®ä¿äºŒè€…æœ€æ–°æ•°æ®æ›´æ–°åˆ°åŒä¸€æ—¥æœŸ")
            raise Exception("æŒ‡æ•°å’ŒETFæ•°æ®æœªåŒæ­¥")
        if rt_date.date() == idx_date.date():
            # è‹¥æ˜¯åŒä¸€äº¤æ˜“æ—¥åˆ™è¯´æ˜å®æ—¶è¡Œæƒ…å·²æ”¶ç›˜ï¼Œç›´æ¥è¿”å›æœ€æ–°æŒ‡æ•°
            result[index_code] = (idx_close, idx_close)
        else:
            ratio = rt_price / etf_close if etf_close else float("nan")
            result[index_code] = (idx_close * ratio, idx_close)

    return result

def build_real_time_date(intraday_factors, est_index_values):
    """
    æ ¹æ®å®æ—¶è¡Œæƒ…æ„é€ å‡ºå®æ—¶å› å­ä¸ä¼°ç®—çš„å®æ—¶æŒ‡æ•°çš„æ•°æ®ï¼Œç”¨äºåç»­æ¨¡å‹é¢„æµ‹
    
    è¿”å›:
    - additional_factor_df: æ ¹æ®å½“å‰æ—¥ç›˜ä¸­å› å­æ”¶ç›Šç‡æ„é€ çš„ DataFrame
    - additional_map: dict[index_code, DataFrame] åŒ…å«ä¼°ç®—ç›˜ä¸­ç‚¹çš„æŒ‡æ•°æ•°æ®
    """
    from datetime import datetime
    from app.service.portfolio_opt import calculate_intraday_factors, compute_portfolio_returns, fetch_realtime_market_data
    from app.data_fetcher.trade_calender_reader import TradeCalendarReader

    current_trade_date = TradeCalendarReader.get_trade_dates(end=datetime.strftime(datetime.today(), "%Y%m%d"))[-1]
    additional_factor_df = pd.DataFrame([intraday_factors.values], columns=intraday_factors.index, index=[current_trade_date])
    additional_factor_df.index = pd.to_datetime(additional_factor_df.index, format='%Y-%m-%d').date
    additional_factor_df.index.name = "date"

    additional_map = {}
    for index_code, (value, pre_value) in est_index_values.items():
        df = pd.DataFrame({
            "index_code": [index_code],
            "date": [current_trade_date],
            "open": [value],
            "close": [value],
            "high": [value],
            "low": [value],
            "change_percent": value / pre_value - 1,
            "change": value - pre_value
        })
        df["date"] = pd.to_datetime(df["date"], format='%Y-%m-%d').dt.date
        additional_map[index_code] = df

    return additional_factor_df, additional_map


def optimize_allocation(additional_factor_df: pd.DataFrame, additional_map: dict[str, pd.DataFrame], asset_source_map: dict, code_factors_map: dict, 
                        trade_date: str, post_view_tau: float, variance: float, view_codes: List[str] = None, window: int = 20, view_var_scale: float = 0.7, prior_mix: float = 0.3):
    """æ ¹æ®é¢„æµ‹æ”¶ç›Šæ‰§è¡Œç»„åˆä¼˜åŒ–ï¼Œè¾“å‡ºæœ€ä¼˜æƒé‡
        additional_factor_df: pd.DataFrame - é¢å¤–çš„å› å­æ•°æ®
        additional_map: dict[str, pd.DataFrame] - é¢å¤–çš„æ•°æ®å­—å…¸
        asset_source_map: dict - èµ„äº§æºæ˜ å°„
        code_factors_map: dict - èµ„äº§å› å­æ˜ å°„
        trade_date: str - äº¤æ˜“æ—¥, æ ¼å¼ä¸º YYYY-MM-DD
        view_codes: List[str] - éœ€è¦ç»“åˆè§‚ç‚¹çš„èµ„äº§ä»£ç 
    """

    from app.data_fetcher.factor_data_reader import FactorDataReader
    from app.data_fetcher.csi_index_data_fetcher import CSIIndexDataFetcher
    from app.dao.fund_info_dao import FundHistDao
    from app.ml.black_litterman_opt_util import load_fund_betas, compute_prior_mu_sigma, compute_prior_mu_fixed_window, build_bl_views, compute_bl_posterior, optimize_mean_variance

    factor_data_reader = FactorDataReader(additional_df=additional_factor_df)
    csi_index_data_fetcher = CSIIndexDataFetcher(additional_map=additional_map)
    dataset_builder = DatasetBuilder(additional_factor_df=additional_factor_df, additional_map=additional_map)
    # 1. æ ¹æ®ä¸åŒæ•°æ®æ¥æºä½¿ç”¨ä¸åŒçš„å¤„ç†æ–¹å¼ï¼Œfactor/index, ä½¿ç”¨Black Litterman æ¨¡å‹è¿›è¡Œè®¡ç®—ï¼Œcashä½¿ç”¨æ»šåŠ¨ä¸€å¹´å¹³å‡çš„æ”¶ç›Šè¿›è¡Œè®¡ç®—ï¼Œhistä¸ºå ä½ç¬¦æš‚æ— è®¡ç®—æ–¹æ¡ˆ
    factor_codes = [code for code, src in asset_source_map.items() if src == "factor"]
    index_codes = [code for code, src in asset_source_map.items() if src == "index"]
    hist_codes = [code for code, src in asset_source_map.items() if src == "hist"]
    cash_codes = [code for code, src in asset_source_map.items() if src == "cash"]

    fund_codes = list(asset_source_map.keys())  # å‚ä¸ä¼˜åŒ–çš„èµ„äº§åˆ—è¡¨
    net_value_df = pd.DataFrame()
    # åŠ è½½å„èµ„äº§çš„æ”¶ç›Šå‡€å€¼æ›²çº¿
    if factor_codes:
        df_beta = load_fund_betas(factor_codes, trade_date, lookback_days=365)
        df_factors = factor_data_reader.read_daily_factors(end=trade_date)[["MKT", "SMB", "HML", "QMJ"]].dropna()
        for code in factor_codes:
            beta = df_beta.loc[code].values
            cumret = df_factors.values @ beta
            net_value_df[code] = (1 + pd.Series(cumret, index=df_factors.index)).cumprod()

    for code in index_codes:
        df = csi_index_data_fetcher.get_data_by_code_and_date(code=code, end=trade_date)
        df = df[["date", "close"]].dropna().set_index("date")
        df = df.sort_index()
        net_value_df[code] = df["close"]

    dao = FundHistDao._instance
    for code in hist_codes:
        df = dao.select_dataframe_by_code(code, end_date=trade_date)
        df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
        net_value_df[code] = df["net_value"]

    for code in cash_codes:
        df = dao.select_dataframe_by_code(code, end_date=trade_date)
        df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
        net_value_df[code] = df["net_value"]

    net_value_df = net_value_df.ffill().sort_index()

    # 2. æ„é€ å…ˆéªŒæ”¶ç›Šä¸åæ–¹å·®çŸ©é˜µï¼ˆä½¿ç”¨å‡€å€¼æ›²çº¿ï¼‰
    mu_dummy, Sigma_full, code_list_mu = compute_prior_mu_sigma(
        net_value_df,
        horizon_days=window,
        lookback_years=8.0,
        method="linear",
        asset_source_map=asset_source_map,

    )
    fund_indices = [code_list_mu.index(code) for code in fund_codes]
    mu_dummy_aligned = mu_dummy[fund_indices]
    Sigma_full = Sigma_full[np.ix_(fund_indices, fund_indices)]
    mu_dict = {code: mu_dummy_aligned[i] for i, code in enumerate(fund_codes)}

    # ä»code_factors_mapæ‰¾å‡º10Ybondå¯¹åº”çš„æŒ‡æ•°ä»£ç 
    ten_year_bond_codes = [code for code, factors in code_factors_map.items() if "10YBOND" in factors]
    if not ten_year_bond_codes:
        raise ValueError("10Ybond must have at least one asset code")
    ten_year_bond_index_code = ten_year_bond_codes[0]

    # ====== æ–°å¢ï¼šå› å­å±‚ BL â†’ èµ„äº§ Î¼_post ======
    # ten_year_bond_index_code è¿™é‡Œéœ€è¦ä½ æŒ‰ç…§å®é™…ä»£ç å¡«ï¼Œä¾‹å¦‚ "H11006.CSI" ä¹‹ç±»
    if post_view_tau > 0:
        mu_post_full, code_list_mu_post, mu_factor_post_dict = compute_asset_mu_from_factor_bl(
            asset_source_map=asset_source_map,
            code_factors_map=code_factors_map,
            asset_codes=view_codes,
            trade_date=trade_date,
            dataset_builder=dataset_builder,          # ä½ ç°æœ‰ç”¨äº get_softprob_dict çš„å®ä¾‹
            ten_year_bond_index_code=ten_year_bond_index_code,       # â˜… çœŸå®çš„ 10Y æŒ‡æ•°ä»£ç 
            horizon_days=20,
            lookback_years=8.0,
            tau=post_view_tau,
            alpha_10ybond=0.3,
            beta_lookback_days=250,
            view_var_scale=view_var_scale,
            prior_mix=prior_mix,
        )

        # ç°åœ¨é¡ºåºæ˜¯code_list_mu_postï¼Œä¸fund_codeså¯¹é½
        code_idx_map = {code: i for i, code in enumerate(code_list_mu_post)}
        for code in fund_codes:
            if code in code_idx_map:
                mu_dict[code] = mu_post_full[code_idx_map[code]]

    # è®¡ç®—ç°é‡‘ç±»èµ„äº§çš„å¹³å‡æ”¶ç›Šä»…ç”¨æ»šåŠ¨æœ€è¿‘ä¸€å¹´çš„æ•°æ®è¿›è¡Œè®¡ç®—ï¼Œç”±äºè®¡ç®—æ–¹å¼ä¸å…¶å®ƒèµ„äº§ä¸åŒï¼Œè¿™é‡Œå•ç‹¬å¤„ç†
    cash_net_value_df = net_value_df[cash_codes].dropna()
    cash_mu_series = compute_prior_mu_fixed_window(cash_net_value_df, window=window, lookback_days=252, method="linear")
    for code in cash_codes:
        mu_dict[code] = cash_mu_series[code]
    
    # === ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹åˆ†æé»„é‡‘æœŸè´§ç»“æ„ï¼Œå¾—åˆ°æœŸæœ›æ”¶ç›Šç‡ï¼Œè¦†ç›–mu_post_fullä¸­çš„é»„é‡‘æ”¶ç›Šç‡
    try:
        # ä»code_factors_mapæ‰¾å‡ºGOLDå¯¹åº”çš„æŒ‡æ•°ä»£ç 
        gold_codes = [code for code, factors in code_factors_map.items() if "GOLD" in factors]
        if not gold_codes:
            raise ValueError("GOLD must have at least one asset code")
        gold_code = gold_codes[0]
        gold_idx = fund_codes.index(gold_code)
        gv = GoldViewLLM()
        res = gv.generate_view(gold_code, pd.to_datetime(trade_date).date())
        if res.expected_return is not None and res.view != "no_view":
            mu_dict[gold_code] = res.expected_return
        else:
            logger.warning(f"å¤§æ¨¡å‹æœªè¿”å› {gold_code} çš„è§‚ç‚¹é¢„æµ‹ï¼Œä½¿ç”¨å…ˆéªŒæ”¶ç›Šç‡è¿›è¡Œä¼˜åŒ–")
    except Exception as e:
        logger.error(e)
        # å¤§æ¨¡å‹æ— æ³•å›æº¯å†å²æ•°æ®è¿›è¡Œåˆ†æï¼Œç›´æ¥ç”¨å…ˆéªŒ

    mu_post_full = np.array([mu_dict[code] for code in fund_codes], dtype=float)

    # === Î± è°ƒæ•´ï¼ˆä¸€æ¬¡æ€§æ°´å¹³é¡¹ï¼Œä¸è¿›å…¥åæ–¹å·®ï¼‰,è¿™é‡Œçš„Î±æŒ‡çš„æ˜¯å› å­å½’å› åˆ†æåå‰©ä¸‹çš„å¸¸æ•°é¡¹ ===
    fund_const = load_fund_const(factor_codes, trade_date)
    const_dict = fund_const.rolling(window=window, min_periods=window).sum().dropna(how='all').mean().to_dict()
    const_dict = _robust_clip_const(const_dict)
    lambda_alpha = 0.2  # å¯è°ƒï¼š0.1~0.3 è¾ƒç¨³å¥

    # éfactorç±»å‹èµ„äº§æ²¡æœ‰constï¼Œé»˜è®¤ä¸º0
    alpha_day = np.array([const_dict.get(code, 0.0) for code in fund_codes], dtype=float)

    # åªè°ƒæ•´ Î¼ï¼Œä¸è°ƒæ•´ Î£ï¼Œé¿å…â€œalpha ä¸€è¨€å ‚â€çš„æ³¢åŠ¨æ”¾å¤§
    mu_post_full = mu_post_full + lambda_alpha * alpha_day
    
    # 4. Max Sharpe ç»„åˆä¼˜åŒ–
    # weights, expected_return, expected_vol = optimize_max_sharpe(mu_post_full, Sigma_full)
    weights, expected_return, expected_vol = optimize_mean_variance(mu_post_full, Sigma_full, variance)

    return {
        'codes': fund_codes,
        'weights': dict(zip(fund_codes, weights)),
        'expected_return': expected_return,
        'expected_volatility': expected_vol,
        'sharpe_ratio': expected_return / expected_vol,
        'cov_matrix': Sigma_full,
    }

def output_optimized_portfolio(portfolio_id: int, portfolio_plan: dict, alpha: float = 0.1):
    """ä¿å­˜æˆ–æ‰“å°æœ€ç»ˆæœ€ä¼˜ç»„åˆæƒé‡ï¼Œå¹¶å°† ewma å¹³æ»‘åçš„ç»“æœå†™å…¥æ•°æ®åº“"""
    # è·å–å½“å‰å’Œå‰ä¸€äº¤æ˜“æ—¥
    trade_dates = TradeCalendarReader.get_trade_dates(end=datetime.today().strftime("%Y%m%d"))
    if len(trade_dates) < 2:
        raise ValueError("äº¤æ˜“æ—¥ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œæƒé‡å¹³æ»‘")

    prev_date = trade_dates[-2]
    today_date = trade_dates[-1]

    # æŸ¥è¯¢æ˜¨æ—¥æƒé‡
    w_prev = query_weights_by_date(date=prev_date, portfolio_id=portfolio_id)["weights"]

    # å½“å‰æƒé‡
    w_today = portfolio_plan["weights"]

    # åˆå¹¶èµ„äº§åˆ—è¡¨
    all_assets = set(w_today.keys()).union(w_prev.keys())

    # è®¡ç®—å¹³æ»‘æƒé‡
    w_smooth = {
        code: round(alpha * w_today.get(code, 0.0) + (1 - alpha) * w_prev.get(code, 0.0), 8)
        for code in all_assets
    }

    cov_matrix = portfolio_plan['cov_matrix']
    codes = portfolio_plan['codes']
    additional_assets = [code for code in all_assets if code not in portfolio_plan['codes']]

    # å°†cov_matrixå’ŒcodesæŒ‰åˆå¹¶åçš„åˆå¹¶èµ„äº§åˆ—è¡¨æ‰©å±•ï¼Œcov_matrixå¤šå‡ºæ¥çš„ä½ç½®å¡«å……0
    additional_size = len(additional_assets)
    cov_matrix = np.pad(cov_matrix, ((0, additional_size), (0, additional_size)), 'constant', constant_values=0.0)
    codes = codes + additional_assets

    store_portfolio(portfolio_id, pd.to_datetime("today").strftime("%Y-%m-%d"), w_today, w_smooth, cov_matrix, codes)
    return w_smooth


factor_data_reader = FactorDataReader()
csi_index_data_fetcher = CSIIndexDataFetcher()

def build_price_df(asset_source_map: dict, start: str, end: str) -> pd.DataFrame:
    """
    æ„é€ ç»„åˆèµ„äº§çš„å‡€å€¼æ›²çº¿ï¼šfactorèµ„äº§ä½¿ç”¨å› å­æš´éœ²ç”Ÿæˆï¼Œindexèµ„äº§ä½¿ç”¨çœŸå®æŒ‡æ•°è¡Œæƒ…
    """
    df_factors = factor_data_reader.read_daily_factors(start=start, end=end)[["MKT", "SMB", "HML", "QMJ"]].dropna()

    net_value_df = pd.DataFrame(index=df_factors.index)
    dao = FundHistDao._instance
    for code, src in asset_source_map.items():
        if src == "factor":
            beta_df = _load_betas_by_code(code)
            if beta_df.empty:
                logger.warning(f"âš ï¸ {code} å› å­æš´éœ²ç¼ºå¤±ï¼Œè·³è¿‡")
                continue
            beta_df = beta_df.reindex(df_factors.index).bfill()
            ret = (beta_df * df_factors).sum(axis=1)
            net_value_df[code] = (1 + pd.Series(ret, index=df_factors.index)).cumprod()
        elif src == "index":
            df = csi_index_data_fetcher.get_data_by_code_and_date(code=code)
            df = df[["date", "close"]].dropna().set_index("date").sort_index()
            net_value_df[code] = df["close"]
        elif src == "hist":
            df = dao.select_dataframe_by_code(code)
            df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
            net_value_df[code] = df["net_value"]
        elif src == "cash":
            df = dao.select_dataframe_by_code(code)
            df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
            net_value_df[code] = df["net_value"]
        else:
            logger.warning(f"æœªçŸ¥èµ„äº§ç±»å‹ {code}: {src}")

    net_value_df = net_value_df.dropna(how='all')
    net_value_df = net_value_df / net_value_df.iloc[0]
    return net_value_df.ffill()


def optimize_portfolio_history(portfolio_id: int, start_date: str = None, end_date: str = None):
    asset_info = get_portfolio_assets(portfolio_id)
    asset_source_map = asset_info["asset_source_map"]
    code_factors_map = asset_info["code_factors_map"]
    view_codes = asset_info["view_codes"]
    params = asset_info["params"]
    if params is None or "post_view_tau" not in params or "alpha" not in params or "variance" not in params:
        raise Exception("Invalid params, please set post_view_tau and alpha and variance in params")
    post_view_tau = float(params["post_view_tau"])
    variance = float(params["variance"])
    alpha = float(params["alpha"])

    if not end_date:
        end_date = CalendarFetcher().get_trade_date(end=pd.to_datetime("today").strftime("%Y%m%d"), format="%Y-%m-%d", limit=1, ascending=False)[0]

    if not start_date:
        latest_portfolio = query_latest_portfolio_by_id(portfolio_id)
        logging.info("ğŸ” è·å–æœ€åä¸€æ¬¡ä¼˜åŒ–çš„ç»„åˆæƒé‡")
        if latest_portfolio.empty:
            raise ValueError("æ²¡æœ‰å†å²ä¼˜åŒ–æƒé‡")
        prev_weights = latest_portfolio["weights_ewma"]
            
        # start_date = (pd.to_datetime(latest_portfolio["date"]) + pd.Timedelta(days=1)).strftime("%Y-%m-%d")
        start_date = CalendarFetcher().get_next_trade_date(pd.to_datetime(latest_portfolio["date"]).strftime("%Y%m%d"), format="%Y-%m-%d")
        logging.info(f"ä½¿ç”¨æœ€åä¸€æ¬¡ä¼˜åŒ–çš„æ—¥æœŸçš„T+1æ—¥ {start_date} ä½œä¸ºèµ·å§‹æ—¥æœŸ")
    else:
        latest_portfolio = query_latest_portfolio_by_id(portfolio_id, start_date)
        if latest_portfolio.empty:
            prev_weights = None
            logger.warning(f"âš ï¸ {portfolio_id} æ²¡æœ‰å†å²ä¼˜åŒ–æƒé‡")
        else:
            prev_weights = latest_portfolio["weights_ewma"]

    all_dates = CalendarFetcher().get_trade_date(start=start_date.replace("-", ""), end=end_date.replace("-", ""), format="%Y-%m-%d", ascending=True)

    logging.info("ğŸ“Š å¼€å§‹æ¯æ—¥ optimize + ewma å¹³æ»‘ + å…¥åº“")
    for dt in tqdm(all_dates):
        try:
            optimize_result = optimize(
                asset_source_map=asset_source_map,
                code_factors_map=code_factors_map,
                trade_date=dt,
                post_view_tau=post_view_tau,
                variance=variance,
                window=20,
                view_codes=view_codes
            )

            w_today = optimize_result["weights"]
            cov_matrix = optimize_result["cov_matrix"]
            codes = optimize_result["codes"]
            
            if prev_weights is None:
                prev_weights = w_today
            
            all_codes = set(w_today.keys()).union(prev_weights.keys())

            w_ewma = {
                code: round(alpha * w_today.get(code, 0.0) + (1 - alpha) * prev_weights.get(code, 0.0), 8)
                for code in all_codes
            }

            additional_assets = [code for code in all_codes if code not in optimize_result["codes"]]
            # å°†cov_matrixå’ŒcodesæŒ‰åˆå¹¶åçš„åˆå¹¶èµ„äº§åˆ—è¡¨æ‰©å±•ï¼Œcov_matrixå¤šå‡ºæ¥çš„ä½ç½®å¡«å……0
            additional_size = len(additional_assets)
            cov_matrix = np.pad(cov_matrix, ((0, additional_size), (0, additional_size)), 'constant', constant_values=0.0)
            codes = codes + additional_assets

            prev_weights = w_ewma.copy()

            store_portfolio(portfolio_id, dt, w_today, w_ewma, cov_matrix, codes)

        except Exception as e:
            logger.warning(f"âš ï¸ {dt} è°ƒä»“å¤±è´¥: {e}")
            continue

def compute_diverge(portfolio_id: int, trade_date: str, current_w: dict, target_w: dict) -> float:
    """
    è®¡ç®—å½“å‰ç»„åˆå’Œç›®æ ‡ç»„åˆä¹‹é—´çš„åç¦»åº¦ï¼ˆè·Ÿè¸ªè¯¯å·®ï¼‰
    TE = sqrt((w - w*)^T Î£ (w - w*))

    :param portfolio_id: ç»„åˆ ID
    :param trade_date: æ—¥æœŸï¼ˆæ ¼å¼ 'YYYY-MM-DD'ï¼‰
    :param current_w: å½“å‰ç»„åˆæƒé‡ dict[asset] = weight
    :param target_w: ç›®æ ‡ç»„åˆæƒé‡ dict[asset] = weight
    :return: è·Ÿè¸ªè¯¯å·®ï¼ˆTracking Errorï¼‰
    """
    codes, cov = query_cov_matrix_by_date(trade_date, portfolio_id)

    # å°†å½“å‰å’Œç›®æ ‡æƒé‡æ˜ å°„åˆ° codes é¡ºåºçš„å‘é‡ï¼ˆæ²¡æœ‰çš„è®¾ä¸º 0ï¼‰
    current_vec = np.array([current_w.get(code, 0.0) for code in codes])
    target_vec = np.array([target_w.get(code, 0.0) for code in codes])

    # è®¡ç®—å·®å¼‚å‘é‡
    diff = current_vec - target_vec

    # TE = sqrt(diff.T * Î£ * diff)
    tracking_error = np.sqrt(diff.T @ cov @ diff)

    return tracking_error

def _robust_clip_const(const_dict: dict) -> dict:
    """
    è¾“å…¥ const_dictï¼ˆ{code: const}ï¼‰ï¼Œå°†æ‰€æœ‰ value æŒ‰ (å‡å€¼ Â± 3*æ ‡å‡†å·®) åšè£å‰ªï¼Œ
    è¿”å›è£å‰ªåçš„æ–° dictã€‚ä¸æ”¹å˜åŸ dictã€‚

    è¯´æ˜ï¼š
    - å‡å€¼ä¸æ ‡å‡†å·®ä½¿ç”¨ np.nanmean / np.nanstd è®¡ç®—ï¼ˆå¿½ç•¥ä¸å¯è½¬ä¸º float æˆ– NaN çš„å€¼ï¼‰ã€‚
    - å¯¹äºæ— æ³•è½¬æˆ float çš„å€¼ï¼ˆå¦‚ Noneã€å­—ç¬¦ä¸²éæ•°å€¼ï¼‰ï¼ŒåŸæ ·ä¿ç•™ã€‚
    """
    if not const_dict:
        return {}

    # æ”¶é›†æ•°å€¼ï¼Œæ— æ³•è½¬ float çš„è®°ä¸º NaNï¼ˆåç»­åœ¨ mean/std ä¸­å¿½ç•¥ï¼‰
    vals = []
    for v in const_dict.values():
        try:
            vals.append(float(v))
        except Exception:
            vals.append(np.nan)

    # è‹¥å…¨æ˜¯ NaNï¼Œåˆ™ç›´æ¥è¿”å›åŸ dict
    if not np.isfinite(np.nanmean(vals)):
        return dict(const_dict)

    mu = float(np.nanmean(vals))
    sigma = float(np.nanstd(vals))
    lo, hi = mu - 2.0 * sigma, mu + 2.0 * sigma

    # é€é¡¹è£å‰ªï¼›ä¸å¯è½¬ float çš„å€¼åŸæ ·è¿”å›
    clipped = {}
    for k, v in const_dict.items():
        try:
            x = float(v)
            # np.clip å¯¹ NaN ä¼šè¿”å› NaNï¼Œè¿™é‡Œä¿æŒä¸€è‡´
            clipped[k] = float(np.clip(x, lo, hi)) if np.isfinite(x) else x
        except Exception:
            clipped[k] = v

    return clipped