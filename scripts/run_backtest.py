import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import pandas as pd
import numpy as np
import vectorbt as vbt
from datetime import datetime
from tqdm import tqdm
import os
import logging

from app import create_app
from scripts.optimize_portfolio import optimize
from app.data_fetcher.factor_data_reader import FactorDataReader
from app.data_fetcher.csi_index_data_fetcher import CSIIndexDataFetcher
from app.dao.fund_info_dao import FundHistDao
from numba import njit
from vectorbt.portfolio.enums import Direction, OrderStatus, NoOrder, CallSeqType, SizeType
from vectorbt.portfolio import nb
from app.database import get_db
from app.models.service_models import PortfolioWeights
import json
from app.data_fetcher.trade_calender_reader import TradeCalendarReader
from app.backtest.backtest_engine import run_backtest as run_backtest_engine
from app.backtest.backtest_engine import BacktestConfig
from app.dao.betas_dao import FundBetaDao
from app.service.portfolio_crud import query_weights_by_date, store_portfolio
from app.service.portfolio_assets_service import get_portfolio_assets
from app.service.portfolio_opt import compute_diverge

app = create_app()
logger = logging.getLogger(__name__)
factor_data_reader = FactorDataReader()
csi_index_data_fetcher = CSIIndexDataFetcher()
sell_fee_rate = 0.0005
slippage_rate = 0.0
portfolio_id = 1

# èµ„äº§é…ç½®
asset_info = get_portfolio_assets(portfolio_id)
asset_source_map = asset_info["asset_source_map"]
code_factors_map = asset_info["code_factors_map"]
for code, src in asset_source_map.items():
    if src == "factor":
        code_factors_map[code] = ["MKT", "SMB", "HML", "QMJ"]

view_codes = asset_info["view_codes"]

params = asset_info["params"]
if params is None or "post_view_tau" not in params or "alpha" not in params or "variance" not in params:
    raise Exception("Invalid params, please set post_view_tau and alpha and variance in params")
post_view_tau = float(params["post_view_tau"])
view_var_scale= float(params["view_var_scale"])
prior_mix=float(params["prior_mix"])
variance = float(params["variance"])
alpha = float(params["alpha"])

def load_fund_betas(code):
    df = FundBetaDao.select_by_code_date(code, None)
    df = df.set_index("date", drop=True)
    return df[["MKT", "SMB", "HML", "QMJ"]]

def load_latest_fund_betas(codes):
    one_year_ago = (pd.to_datetime("today") - pd.DateOffset(years=1)).strftime('%Y-%m-%d')
    df = FundBetaDao.get_latest_fund_betas(fund_type_list=["è‚¡ç¥¨å‹"], invest_type_list=["è¢«åŠ¨æŒ‡æ•°å‹", "å¢å¼ºæŒ‡æ•°å‹"], found_date_limit=one_year_ago)
    df = df.set_index("code", drop=True)
    df = df[df.index.isin(codes)]
    return df[["MKT", "SMB", "HML", "QMJ"]]


def build_price_df(asset_source_map: dict, start: str, end: str) -> pd.DataFrame:
    """
    æ„é€ ç»„åˆèµ„äº§çš„å‡€å€¼æ›²çº¿ï¼šfactorèµ„äº§ä½¿ç”¨å› å­æš´éœ²ç”Ÿæˆï¼Œindexèµ„äº§ä½¿ç”¨çœŸå®æŒ‡æ•°è¡Œæƒ…
    """
    df_factors = factor_data_reader.read_daily_factors(start=start, end=end)[["MKT", "SMB", "HML", "QMJ"]].dropna()

    net_value_df = pd.DataFrame(index=df_factors.index)
    dao = FundHistDao._instance
    for code, src in asset_source_map.items():
        if src == "factor":
            beta_df = load_fund_betas(code)
            if beta_df.empty:
                logger.warning(f"âš ï¸ {code} å› å­æš´éœ²ç¼ºå¤±ï¼Œè·³è¿‡")
                continue
            beta_df = beta_df.reindex(df_factors.index).bfill()
            ret = (beta_df * df_factors).sum(axis=1)
            net_value_df[code] = (1 + pd.Series(ret, index=df_factors.index)).cumprod()
        elif src == "index":
            df = csi_index_data_fetcher.get_data_by_code_and_date(code=code)
            df = df[["date", "close"]].dropna().set_index("date").sort_index()
            net_value_df[code] = df["close"]
        elif src == "hist":
            df = dao.select_dataframe_by_code(code)
            df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
            net_value_df[code] = df["net_value"]
        elif src == "cash":
            df = dao.select_dataframe_by_code(code)
            df = df[["date", "net_value"]].dropna().set_index("date").sort_index()
            net_value_df[code] = df["net_value"]
        else:
            logger.warning(f"æœªçŸ¥èµ„äº§ç±»å‹ {code}: {src}")

    net_value_df = net_value_df.dropna(how='all')
    net_value_df = net_value_df / net_value_df.bfill().iloc[0]
    return net_value_df.ffill()


def run_backtest(start="2019-12-22", end="2024-12-22", window=20):
    out_dir = f"./fund_portfolio_bt_result/{datetime.today().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(out_dir, exist_ok=True)
    with app.app_context():
        print("ğŸ” å¼€å§‹æ„å»ºä»·æ ¼æ•°æ®")
        price_df = build_price_df(asset_source_map, start, end)
        all_dates = price_df.index
        assets = list(asset_source_map.keys())
        weights_dict = {d: {} for d in all_dates}

        prev_weights = None  # ä¸Šä¸€æ—¥çš„å¹³æ»‘æƒé‡

        print("ğŸ“Š å¼€å§‹æ¯æ—¥ optimize + ewma å¹³æ»‘ + å…¥åº“")
        for dt in tqdm(all_dates):
            try:
                portfolio_plan = optimize(
                    asset_source_map=asset_source_map,
                    code_factors_map=code_factors_map,
                    trade_date=dt.strftime('%Y-%m-%d'),
                    post_view_tau = post_view_tau,
                    variance = variance,
                    window=window,
                    view_codes=view_codes,
                    view_var_scale= 0.7, prior_mix=0.3
                )

                w_today = portfolio_plan["weights"]
                cov_matrix = portfolio_plan["cov_matrix"]
                codes = portfolio_plan["codes"]

                # å¦‚æœç¬¬ä¸€å¤©ï¼Œä»æ•°æ®åº“å°è¯•è¯»å–å‰ä¸€æ—¥å¹³æ»‘å€¼
                if prev_weights is None:
                    trade_dates = TradeCalendarReader.get_trade_dates(end=dt.strftime("%Y-%m-%d"))
                    if len(trade_dates) >= 2:
                        prev_trade_date = trade_dates[-2]
                    else:
                        raise ValueError("äº¤æ˜“æ—¥ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œæƒé‡å¹³æ»‘")
                    
                    prev_weights = query_weights_by_date(prev_trade_date, portfolio_id)["weights"]

                all_codes = set(w_today.keys()).union(prev_weights.keys())
                w_ewma = {
                    code: round(alpha * w_today.get(code, 0.0) + (1 - alpha) * prev_weights.get(code, 0.0), 8)
                    for code in all_codes
                }

                additional_assets = [code for code in all_codes if code not in portfolio_plan["codes"]]
                # å°†cov_matrixå’ŒcodesæŒ‰åˆå¹¶åçš„åˆå¹¶èµ„äº§åˆ—è¡¨æ‰©å±•ï¼Œcov_matrixå¤šå‡ºæ¥çš„ä½ç½®å¡«å……0]
                additional_size = len(additional_assets)
                cov_matrix = np.pad(cov_matrix, ((0, additional_size), (0, additional_size)), 'constant', constant_values=0.0)
                codes = codes + additional_assets

                weights_dict[dt] = pd.Series(w_ewma)
                prev_weights = w_ewma.copy()
                
                store_portfolio(portfolio_id, dt, w_today, w_ewma, cov_matrix, codes)

            except Exception as e:
                logger.warning(f"âš ï¸ {dt.strftime('%Y-%m-%d')} è°ƒä»“å¤±è´¥: {e}")
                continue

        weights_df = pd.DataFrame.from_dict(weights_dict, orient='index')
        weights_df = weights_df.dropna(how='all').fillna(0)
        price_df = price_df.loc[weights_df.index]

        

        # === å¤„ç†æƒé‡åºåˆ— ===
        d = 0.005  # åå·®ç™¾åˆ†æ¯”é˜ˆå€¼
        rebalance_dates = [weights_df.index[0]]
        prev_weight = weights_df.iloc[0]

        for date, current_weight in weights_df.iloc[1:].iterrows():
            avg_ratio = compute_diverge(portfolio_id=portfolio_id, trade_date=date, current_w=prev_weight, target_w=current_weight)

            if avg_ratio > d:
                rebalance_dates.append(date)
                prev_weight = current_weight

        rebalance_dates = pd.DatetimeIndex(rebalance_dates)
        weights_df = weights_df.loc[rebalance_dates]
        weights_df.to_csv(os.path.join(out_dir, "portfolio_weights.csv"))

        print("ğŸ å¼€å§‹æ„å»º Portfolio")

        cfg = BacktestConfig(
            init_cash=100_000_000,
            buy_fee=0.0,
            sell_fee=sell_fee_rate,
            slippage=slippage_rate,
            cash_sharing=True
        )
        result = run_backtest_engine(weights_df, price_df, cfg)

        # 5. æ—¥æ¢æ‰‹ç‡è®¡ç®—å‡½æ•°
        def compute_turnover_rate(portfolio, n: int = 1) -> pd.Series:
            """
            è®¡ç®— n æ—¥å¹³å‡æ¢æ‰‹ç‡ï¼ˆn=1 ä¸ºæ—¥æ¢æ‰‹ç‡ï¼‰ï¼Œé€‚ç”¨äº portfolio.value() è¿”å› Series çš„æƒ…å†µã€‚
            """
            orders = portfolio.orders.records_readable.copy()

            # è®¡ç®—æ¯ç¬”äº¤æ˜“é‡‘é¢
            if 'trade_value' not in orders.columns:
                orders['trade_value'] = orders['Size'].abs() * orders['Price']

            # ç¡®ä¿ Timestamp æ˜¯ datetime ç±»å‹
            orders['date'] = pd.to_datetime(orders['Timestamp'])
            daily_trade_value = orders.groupby('date')['trade_value'].sum()

            # è·å–ç»„åˆæ¯æ—¥å¸‚å€¼ï¼ˆSeriesï¼‰
            portfolio_value = portfolio.value()
            portfolio_value.index = pd.to_datetime(portfolio_value.index)

            # å¯¹é½åè®¡ç®—æ¢æ‰‹ç‡
            aligned = pd.concat([daily_trade_value, portfolio_value], axis=1, join='inner')
            aligned.columns = ['turnover_amt', 'portfolio_value']
            aligned['turnover'] = aligned['turnover_amt'] / aligned['portfolio_value']

            # è¿”å›æ»šåŠ¨æ¢æ‰‹ç‡
            return aligned['turnover'].rolling(n).mean()

        # 6. ç»“æœè¾“å‡º
        # stats = pf.stats()
        turnover_rate = compute_turnover_rate(result["pf"], n=1)
        mean_turnover = turnover_rate[1:].mean() #å»æ‰å»ºä»“é¦–æ—¥çš„æ¢æ‰‹ç‡

        # print(stats)
        print(f"\nğŸ”„ æ—¥å‡æ¢æ‰‹ç‡: {mean_turnover:.4f}")

        result["nav"].to_csv(os.path.join(out_dir, "portfolio_value.csv"))
        result["returns"].to_csv(os.path.join(out_dir, "daily_returns.csv"))
        # stats.to_csv(os.path.join(out_dir, "stats.csv"))
        turnover_rate.to_csv(os.path.join(out_dir, "daily_turnover.csv"))
        result["nav"].vbt.plot(title="æ··åˆèµ„äº§ç»å€ºçº¿").write_html(os.path.join(out_dir, "value_plot.html"))

        print(f"âœ… å›æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š{out_dir}")

from app.service.portfolio_crud import query_all_weights_by_date

def run_backtest_using_db_weights(
    *,
    portfolio_id: int,
    start: str,
    end: str,
    d_threshold: float = 0.005,     # åå·®é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™è§¦å‘è°ƒä»“
    ensure_trade_calendar_union: bool = True  # ä»·æ ¼æŒ‰æƒé‡æ—¥æœŸå¹¶é½ï¼Œç¼ºå¤±ç”¨å‰å€¼ï¼ˆ0æ”¶ç›Šï¼‰
):
    """
    ä½¿ç”¨æ•°æ®åº“ä¸­å·²å­˜çš„å¹³æ»‘æƒé‡ï¼ˆweights_ewmaï¼‰+ çœŸå®èµ„äº§å‡€å€¼è¿›è¡Œå›æµ‹ã€‚
    - ä»…ä½¿ç”¨ PortfolioWeights.weights_ewma
    - å›æµ‹æ—¶é—´åŒºé—´ç”± start/end æŒ‡å®šï¼ˆå«ç«¯ç‚¹ï¼‰
    - è‹¥æŸå¤©æŸèµ„äº§ç¼º NAVï¼šæŒ‰â€œ0æ”¶ç›Šâ€å¤„ç† â†’ å‰å€¼å¡«å……ï¼ˆffillï¼‰
    - è°ƒä»“é¢‘ç‡ï¼šå½“åå·®è¶…è¿‡é˜ˆå€¼æ—¶è°ƒä»“ï¼›å½“èµ„äº§ä»£ç é›†åˆå‘ç”Ÿå˜åŒ–æ—¶å¿…è°ƒä»“
    - ä»·æ ¼æ¥æºï¼šå¯¹æ¶‰åŠåˆ°çš„å…¨éƒ¨èµ„äº§æ„å»º asset_source_mapï¼š
        "H11004.CSI" ä¸ "Au99.99.SGE" â†’ "index"
        "270004.OF" â†’ "cash"
        å…¶ä»–ä»£ç  â†’ "hist"
      build_price_df ä¼šä¸º "hist" è¿”å›å¤æƒç´¯è®¡å‡€å€¼ï¼ˆæ— éœ€é¢å¤–å¤„ç†ï¼‰

    å¯¼å‡ºï¼š
    - portfolio_weights.csv  ï¼ˆå®é™…å‚ä¸å›æµ‹çš„è°ƒä»“æ—¥æƒé‡ï¼‰
    - portfolio_value.csv    ï¼ˆç»„åˆå‡€å€¼ï¼‰
    - daily_returns.csv      ï¼ˆæ—¥æ”¶ç›Šç‡ï¼‰
    - daily_turnover.csv     ï¼ˆæ—¥æ¢æ‰‹ç‡ï¼‰
    - value_plot.html        ï¼ˆå‡€å€¼æ›²çº¿ï¼‰
    - weights_from_db.csv    ï¼ˆDBè¯»å‡ºçš„å®Œæ•´æ—¥åº¦æƒé‡æ˜ç»†ï¼Œä¾¿äºæ ¸å¯¹ï¼‰
    """
    # === 0) è¾“å‡ºç›®å½• ===
    out_dir = f"./fund_portfolio_bt_result/{datetime.today().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(out_dir, exist_ok=True)

    # === 1) ä» DB è¯»å–æƒé‡ï¼ˆä»… weights_ewmaï¼‰===
    print("ğŸ—ƒï¸ ä»æ•°æ®åº“è¯»å–æƒé‡ï¼ˆweights_ewmaï¼‰...")
    df_w_all = query_all_weights_by_date(
        portfolio_id=portfolio_id,
        start_date=start,
        end_date=end,
        fill_missing_zero=True  # ç¼ºå¤±èµ„äº§æƒé‡=0ï¼Œä¾¿äºå¯¹é½
    )
    if df_w_all.empty:
        raise ValueError(f"åœ¨åŒºé—´ {start}~{end} å†…æœªè¯»å–åˆ°ä»»ä½•æƒé‡è®°å½•ï¼ˆportfolio_id={portfolio_id}ï¼‰ã€‚")

    # ä¿å­˜åŸå§‹ï¼ˆä»DBè¯»å‡ºï¼‰çš„æ—¥åº¦æƒé‡è¡¨ï¼Œä¾¿äºæ ¸å¯¹
    df_w_all.sort_index().to_csv(os.path.join(out_dir, "weights_from_db.csv"))
    print(f"âœ… å·²å¯¼å‡º weights_from_db.csvï¼Œå…± {len(df_w_all)} è¡Œã€‚")

    # === 2) æ„é€  asset_source_mapï¼ˆåªè¦†ç›–å›æµ‹åŒºé—´å‡ºç°è¿‡çš„èµ„äº§ä»£ç ï¼‰===
    all_codes = set(df_w_all.columns)
    def _code_to_type(code: str) -> str:
        if code in {"H11004.CSI", "Au99.99.SGE"}:
            return "index"
        if code == "270004.OF":
            return "cash"
        return "hist"

    asset_source_map = {code: _code_to_type(code) for code in all_codes}

    # === 3) æ„å»ºçœŸå®å‡€å€¼ price_dfï¼Œå¹¶æŒ‰â€œ0æ”¶ç›Šâ€è§„åˆ™å¯¹é½ ===
    print("ğŸ’° æ„å»ºèµ„äº§å‡€å€¼æ›²çº¿ï¼ˆbuild_price_dfï¼‰...")
    price_df = build_price_df(asset_source_map, start, end)
    if price_df is None or price_df.empty:
        raise ValueError("price_df ä¸ºç©ºï¼Œæ— æ³•å›æµ‹ã€‚")

    # ä»…ä¿ç•™æƒé‡æ¶‰åŠåˆ°çš„èµ„äº§åˆ—
    missing_cols = all_codes - set(price_df.columns)
    if missing_cols:
        # å¯¹äºç¼ºå¤±ä»·æ ¼çš„èµ„äº§ï¼Œæ–°å»ºåˆ—å¹¶ç”¨ NaNï¼Œåç»­ ffill
        for c in missing_cols:
            price_df[c] = np.nan
        price_df = price_df[df_w_all.columns]  # åˆ—é¡ºåºä¸æƒé‡å¯¹é½
    else:
        price_df = price_df[df_w_all.columns]

    # å°†ä»·æ ¼ç´¢å¼•é™åˆ¶åœ¨ DB æƒé‡çš„æ—¥æœŸèŒƒå›´å†…çš„äº¤é›†
    # æ³¨æ„ï¼šæ ¹æ®ä½ çš„è§„åˆ™ï¼Œè‹¥æŸæ—¥æŸèµ„äº§æ—  NAVï¼Œ0 æ”¶ç›Š â†’ ffill
    if ensure_trade_calendar_union:
        # ä»¥â€œæƒé‡æ—¥æœŸâ€ä¸ºä¸»ï¼Œå¼ºåˆ¶æŠŠä»·æ ¼ reindex åˆ°æƒé‡æ—¥æœŸä¸Šï¼Œå† ffill
        price_df = price_df.reindex(df_w_all.index).sort_index()

    # å‰å‘å¡«å……ï¼šç¼ºå¤±ä»·æ ¼ç”¨æœ€è¿‘ä¸€æ¬¡ä»·æ ¼ï¼ˆå³ 0 æ”¶ç›Šï¼‰
    price_df = price_df.ffill()

    # è‹¥èµ·å§‹æ—¥ä»æœ‰ NaNï¼ˆå‰ä¸€æ—¥å®Œå…¨æ²¡æœ‰å†å²ä»·æ ¼ï¼‰ï¼Œå¯ç”¨é¦–ä¸ªé NaN å€¼å‘åå¡«ï¼ˆé¿å…å›æµ‹å¼•æ“æŠ¥é”™ï¼‰
    price_df = price_df.fillna(method="bfill", axis=0)

    # å†æ¬¡æ ¡éªŒ
    if price_df.isna().any().any():
        # ä»å­˜åœ¨ NaNï¼Œè¯´æ˜æŸäº›èµ„äº§åœ¨æ•´ä¸ªåŒºé—´éƒ½æ²¡æœ‰ä»·æ ¼ï¼›æŠŠå…¶å¯¹åº”æƒé‡å¼ºåˆ¶ç½® 0
        cols_all_nan = [c for c in price_df.columns if price_df[c].isna().all()]
        if cols_all_nan:
            logger.warning(f"è¿™äº›èµ„äº§åœ¨åŒºé—´å†…æ²¡æœ‰ä»»ä½•ä»·æ ¼æ•°æ®ï¼Œå°†åœ¨æƒé‡ä¸­ç½®é›¶å¹¶ä»ä»·æ ¼ä¸­å‰”é™¤: {cols_all_nan}")
            df_w_all[cols_all_nan] = 0.0
            price_df = price_df.drop(columns=cols_all_nan)

    # å†æ¬¡å¯¹é½åˆ—
    shared_cols = [c for c in df_w_all.columns if c in price_df.columns]
    df_w_all = df_w_all[shared_cols]
    price_df = price_df[shared_cols]

    # === 4) å¤„ç†æƒé‡åºåˆ— â†’ é€‰æ‹©è°ƒä»“æ—¥ ===
    print("ğŸ§­ é€‰æ‹©è°ƒä»“æ—¥ï¼ˆåå·®é˜ˆå€¼ & ä»£ç é›†åˆå˜åŒ–å¿…è°ƒä»“ï¼‰...")
    rebalance_dates = []
    prev_weight = None
    prev_cols_set = None

    for date, w_row in df_w_all.iterrows():
        w_row = w_row.fillna(0.0)

        # ç¬¬ä¸€å¤©å¿…è°ƒä»“
        if prev_weight is None:
            rebalance_dates.append(date)
            prev_weight = w_row
            prev_cols_set = set(w_row.index[w_row.values != 0.0])
            continue

        # 1) è‹¥ä»£ç é›†åˆå˜åŒ–ï¼šå¿…è°ƒä»“
        curr_cols_set = set(w_row.index[w_row.values != 0.0])
        if curr_cols_set != prev_cols_set:
            rebalance_dates.append(date)
            prev_weight = w_row
            prev_cols_set = curr_cols_set
            continue

        # 2) åå·®é˜ˆå€¼ï¼šä½¿ç”¨ä½ å·²æœ‰çš„ compute_divergeï¼ˆä¿æŒé€»è¾‘ä¸€è‡´ï¼‰
        avg_ratio = compute_diverge(
            portfolio_id=portfolio_id,
            trade_date=date,
            current_w=prev_weight,
            target_w=w_row
        )
        if avg_ratio > d_threshold:
            rebalance_dates.append(date)
            prev_weight = w_row
            prev_cols_set = curr_cols_set

    rebalance_dates = pd.DatetimeIndex(rebalance_dates)
    weights_df = df_w_all.loc[rebalance_dates].copy()

    # å¯¼å‡ºç”¨äºå›æµ‹çš„è°ƒä»“æƒé‡
    weights_df.to_csv(os.path.join(out_dir, "portfolio_weights.csv"))
    print(f"âœ… è°ƒä»“æ—¥å…± {len(weights_df)} ä¸ªï¼Œå·²å¯¼å‡º portfolio_weights.csvã€‚")

    # å¯¹é½ price_df çš„æ—¶é—´ç´¢å¼•ï¼ˆå¼•æ“é€šå¸¸éœ€è¦å®Œæ•´çš„æ—¥åº¦ä»·æ ¼åºåˆ—ï¼‰
    # price_df å·²ç» reindex åˆ° df_w_all.index å¹¶ ffillï¼Œè¿™é‡Œç¡®ä¿åŒºé—´å®Œæ•´ï¼š
    price_df = price_df.loc[df_w_all.index.min(): df_w_all.index.max()]

    # === 5) è¿è¡Œå›æµ‹å¼•æ“ ===
    print("ğŸš€ è¿è¡Œå›æµ‹å¼•æ“...")
    cfg = BacktestConfig(
        init_cash=100_000_000,
        buy_fee=0.0,
        sell_fee=sell_fee_rate,
        slippage=slippage_rate,
        cash_sharing=True
    )
    result = run_backtest_engine(weights_df, price_df, cfg)

    # === 7) å¯¼å‡ºç»“æœ ===
    result["nav"].to_csv(os.path.join(out_dir, "portfolio_value.csv"))
    result["returns"].to_csv(os.path.join(out_dir, "daily_returns.csv"))
    result["nav"].vbt.plot(title="ç»„åˆå‡€å€¼æ›²çº¿").write_html(os.path.join(out_dir, "value_plot.html"))

    print(f"âœ… å›æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š{out_dir}")

    return {
        "out_dir": out_dir,
        "rebalance_dates": rebalance_dates,
        "nav": result["nav"],
        "returns": result["returns"],
    }


if __name__ == '__main__':
    # run_backtest_using_db_weights(portfolio_id=2, start='2025-09-02', end='2025-09-25')
    run_backtest(start="2019-10-22", end="2025-10-22", window=20)